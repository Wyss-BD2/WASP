{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321da3b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### WELCOME TO WASP ####\n",
    "### Please refer to the README for instructions ###\n",
    "\n",
    "# Import Packages\n",
    "import os\n",
    "from tkinter import filedialog\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from combat.pycombat import pycombat\n",
    "from umap import UMAP\n",
    "from pydeseq2.dds import DeseqDataSet\n",
    "from pydeseq2.ds import DeseqStats\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'notebook'\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "pyo.init_notebook_mode(connected=True)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bioinfokit import analys, visuz\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# function to check for Total and % Missing\n",
    "def nan_check(data):\n",
    "    total = data.isnull().sum().sort_values(ascending=False)\n",
    "    percent_1 = data.isnull().sum()/data.isnull().count()*100\n",
    "    percent_2 = (np.round(percent_1, 1)).sort_values(ascending=False)\n",
    "    missing_data = pd.concat([total, percent_2], axis=1, keys=['Total Null', '% Missing'])\n",
    "    return missing_data\n",
    "\n",
    "# function to prepend a string to each list element\n",
    "def prepend(list, str):\n",
    "    str += '{0}'\n",
    "    list = [str.format(i) for i in list]\n",
    "    return(list)\n",
    "\n",
    "# function used for removing nested lists\n",
    "def reemovNestings(l):\n",
    "    for i in l:\n",
    "        if type(i) == list:\n",
    "            reemovNestings(i)\n",
    "        else:\n",
    "            output.append(i)\n",
    "\n",
    "# function for selecting number of PCs for 80% Variance explained\n",
    "def find80p(variance):\n",
    "    count = 0\n",
    "    i = 0\n",
    "    while count < 0.80:\n",
    "        count += variance[i]\n",
    "        i += 1\n",
    "    return i\n",
    "\n",
    "# Prompt to select WASP pipeline\n",
    "WASP_pipeline = input('\\n\\nWelcome to WASP (Wyss Analysis Software for Proteomics).\\n\\nPlease choose a pipeline for Dimensionality Reduction and Differential Expression Analysis:\\n\\n0 ----- Single Cell\\n1 ----- Bulk\\n\\n')\n",
    "if WASP_pipeline == '0':\n",
    "    print('\\nWASP for Single Cell Proteomics')\n",
    "else:\n",
    "    print('\\nWASP for Bulk Proteomics')\n",
    "\n",
    "# naming\n",
    "Experiment = input('\\nEnter Experiment ID: ')\n",
    "Plate = input('\\nEnter Condition ID: ')\n",
    "print('\\nChoose Parent Directory')\n",
    "parent_dir = filedialog.askdirectory()\n",
    "Date = pd.to_datetime('today').date()\n",
    "directory = Experiment\n",
    "path = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# input csv\n",
    "print('Open PSM Excel File')\n",
    "PSM = filedialog.askopenfilename()\n",
    "UniProt = pd.read_excel('UniProt.xlsx')\n",
    "\n",
    "# Load PSM as Pandas DataFrame\n",
    "print('Reading PSM file (this make take a few minutes)')\n",
    "df_raw = pd.read_excel(PSM)\n",
    "\n",
    "'''# PSM QA\n",
    "print('\\nPSM Stats:')\n",
    "df_raw.hist(column = 'DeltaM [ppm]')\n",
    "print('\\nAverage Delta M: ', round(df_raw['DeltaM [ppm]'].mean(), 2), 'ppm')\n",
    "df_raw.hist(column = 'Deltam/z [Da]')\n",
    "print('\\nAverage Delta m/z : ', round(df_raw['Deltam/z [Da]'].mean(), 2), 'Da')\n",
    "if df_raw['Checked'].nunique()==1:\n",
    "    print('\\nAll Checked == False? ', df_raw['Checked'].nunique()==1)\n",
    "else:\n",
    "    print(df_raw['Checked'].value_counts())\n",
    "if df_raw['Confidence'].nunique()==1:\n",
    "    print('\\nAll Confidence == High? ', df_raw['Confidence'].nunique()==1)\n",
    "else:\n",
    "    print(df_raw['Confidence'].value_counts())\n",
    "if df_raw['PSM Ambiguity'].nunique()==1:\n",
    "    print('\\nAll PSM Unambiguous? ', df_raw['PSM Ambiguity'].nunique()==1)\n",
    "else:\n",
    "    print('\\nPSM Ambiguity: \\n',df_raw['PSM Ambiguity'].value_counts())\n",
    "df_raw.hist(column= 'Charge')\n",
    "print('\\nAverage Charge: ', round(df_raw['Charge'].mean(), 1))\n",
    "print('\\nAverage RT [min]: ', round(df_raw['RT [min]'].mean(), 1), 'min')\n",
    "df_raw.hist(column = 'RT [min]')\n",
    "df_raw.hist(column = 'Isolation Interference [%]')\n",
    "df_raw.hist(column = 'Average Reporter S/N')'''\n",
    "\n",
    "# Clean DataFrame\n",
    "df = df_raw.rename(columns = {'Abundance: 126': '126', 'Abundance: 127N': '127N', 'Abundance: 127C': '127C',\n",
    "               'Abundance: 128N': '128N', 'Abundance: 128C': '128C', 'Abundance: 129N': '129N',\n",
    "              'Abundance: 129C': '129C', 'Abundance: 130N': '130N', 'Abundance: 130C': '130C',\n",
    "              'Abundance: 131N': '131N', 'Abundance: 131C': '131C', 'Abundance: 132N': '132N',\n",
    "              'Abundance: 132C': '132C', 'Abundance: 133N': '133N', 'Abundance: 133C': '133C',\n",
    "              'Abundance: 134N': '134N', 'Abundance: 134C': '134C', 'Abundance: 135N': '135N'})\n",
    "print('\\nNumber PSM: ' + str(df.shape[0]))\n",
    "\n",
    "# Remove Co-Isolated greater than 60%\n",
    "print('\\nRemoving 60% Co-Isolation')\n",
    "df = df[~(df['Isolation Interference [%]'] >= 59.999)]\n",
    "print('Number PSM: ' + str(df.shape[0]))\n",
    "\n",
    "# Remove Keratin\n",
    "print('Removing Keratin')\n",
    "KRT = pd.read_excel('Keratin.xlsx')\n",
    "KRT = KRT.astype(str)\n",
    "KRT_list = '|'.join(list(KRT.Entry))\n",
    "df = df.loc[~df['Master Protein Accessions'].str.contains(KRT_list, case=False, na=False)]\n",
    "print('Number PSM: ' + str(df.shape[0]))\n",
    "\n",
    "# Remove Contaminants\n",
    "print('Removing Contaminants')\n",
    "c2a = pd.read_csv('Contaminants.csv')\n",
    "c2a = c2a.astype(str)\n",
    "c2a = '|'.join(c2a['1'])\n",
    "df = df.loc[~df['Master Protein Accessions'].str.contains(c2a, case=False, na=False)]\n",
    "\n",
    "# Counts\n",
    "print('\\nCounts:')\n",
    "print('Number PSM: ' + str(df.shape[0]))\n",
    "print('Number of Peptides: ' + str(df['Annotated Sequence'].nunique()))\n",
    "print('Number of Proteins: ' + str(df['Master Protein Accessions'].nunique()))\n",
    "print('\\n')\n",
    "\n",
    "# Check for missing data by Channel\n",
    "print('\\nNull Table')\n",
    "print(nan_check(df))\n",
    "\n",
    "# Prompt to remove channels and drop from DataFrame\n",
    "Bad_channels = input('\\nRemove Channel(s)? \\nEnter: y or n \\n')\n",
    "if Bad_channels == 'y':\n",
    "    print('\\nInput channels separated by a comma (,) NO SPACES')\n",
    "    Remove = input('\\nChannels to Remove: ')\n",
    "    df = df.drop(Remove.split(','), axis=1)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "# Retrieve File ID Info and Remove Bad Injections\n",
    "print('\\nInjection Counts: \\n')\n",
    "abundance = df['File ID'].value_counts()\n",
    "print(abundance)\n",
    "Bad_injections = input('\\nRemove Injection(s)? \\nEnter: y or n \\n')\n",
    "if Bad_injections == 'y':\n",
    "    print('\\nInput File ID separated by a coma (,) NO SPACES')\n",
    "    Inj_Remove = input('\\nInjections to Remove: ')\n",
    "    BI_list = '|'.join(list(Inj_Remove.split(',')))\n",
    "    df = df.loc[~df['File ID'].str.contains(BI_list, case=False, na=False)]\n",
    "else:\n",
    "    pass\n",
    "\n",
    "fid_count = df['File ID'].nunique()\n",
    "print('\\nUnique File ID: ' + str(fid_count))\n",
    "\n",
    "# Identify Case and Control\n",
    "print('\\nInput channels separated by a comma (,) NO SPACES')\n",
    "Case = input('\\nEnter Case: ')\n",
    "Control = input('Enter Control: ')\n",
    "\n",
    "# Create Final DataFrame\n",
    "df = df[['Annotated Sequence', 'Master Protein Accessions', 'File ID']].join(df[Control.split(',')].join(df[Case.split(',')]))\n",
    "dfboxen = df[['Annotated Sequence', 'Master Protein Accessions', 'File ID']].join(df[Control.split(',')].join(df[Case.split(',')]))\n",
    "#DEA_df = df.fillna(0)\n",
    "\n",
    "# Plot Pre-Normalization\n",
    "dfboxen = dfboxen.iloc[:,3:].apply(lambda x: np.log2(x), axis=0)\n",
    "\n",
    "fig = sns.boxenplot(data=dfboxen, orient='h', width_method=\"linear\")\n",
    "plt.xlabel('Relative Abundance')\n",
    "plt.ylabel('Channel')\n",
    "plt.title('Pre-Normalization')\n",
    "plt.savefig(f'{path}/{Experiment}_{Plate}_Pre-Normalization_{Date}.pdf', format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show(fig)\n",
    "\n",
    "# Create Dictionaries for Groupby functions\n",
    "Median = 'median'\n",
    "Mean = 'mean'\n",
    "Sum = 'sum'\n",
    "Case_Median = {k:Median for k in Case.split(',')}\n",
    "Control_Median = {k:Median for k in Control.split(',')}\n",
    "Case_Mean = {k:Mean for k in Case.split(',')}\n",
    "Control_Mean = {k:Mean for k in Control.split(',')}\n",
    "DEA_agg = Control_Median|Case_Median\n",
    "Case_Sum = {k:Sum for k in Case.split(',')}\n",
    "Control_Sum = {k:Sum for k in Control.split(',')}\n",
    "Heatmap_agg = Control_Median|Case_Median\n",
    "\n",
    "### MOR (Median of Ratios) Normalization for Channel Normalization\n",
    "# take the log of data\n",
    "print('\\nPerforming Median of Ratio Normalization for Channel Normalization')\n",
    "log_data = np.log(df.iloc[:,3:])\n",
    "\n",
    "# Take the average of each row\n",
    "log_data['pseudo_reference'] = log_data.apply(lambda x: np.mean(x), axis=1)\n",
    "log_data.reset_index(inplace=True)\n",
    "\n",
    "# filter out proteins with infinity as average\n",
    "filtered_log_data = log_data[log_data['pseudo_reference'] != float('-inf')]\n",
    "\n",
    "# Subtract the protein pseudo-reference from log counts\n",
    "ratio_data = filtered_log_data.iloc[:, 1:-1].apply(lambda x: x - filtered_log_data['pseudo_reference'], axis=0)\n",
    "\n",
    "# Find the Median of the Ratios for each sample\n",
    "sample_medians = ratio_data.median(axis=0)\n",
    "\n",
    "# Convert medians to scaling factors\n",
    "scaling_factors = np.exp(sample_medians)\n",
    "\n",
    "# Divide original counts by scaling factors\n",
    "manually_normalized = df.iloc[:,3:].div(scaling_factors, axis='columns')\n",
    "\n",
    "# Plot Post-Normalization\n",
    "fig2 = sns.boxenplot(data=manually_normalized.apply(lambda x: np.log2(x), axis=0),\n",
    "                     orient='h', width_method=\"linear\")\n",
    "plt.xlabel('Relative Abundance')\n",
    "plt.ylabel('Channel')\n",
    "plt.title('Post-Normalization')\n",
    "plt.savefig(f'{path}/{Experiment}_{Plate}_Post-Normalization_{Date}.pdf', format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show(fig2)\n",
    "\n",
    "### this pipe leads to KNN 50% missing imputation\n",
    "df = df.iloc[:,:3].join(manually_normalized)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# break df and drop NaN\n",
    "treated = df.filter(Case.split(','))\n",
    "treated = df.iloc[:,:3].join(treated)\n",
    "treated = treated.dropna(thresh=round(treated.shape[1]/2))\n",
    "untreated = df.filter(Control.split(','))\n",
    "untreated = df.iloc[:,:3].join(untreated)\n",
    "untreated = untreated.dropna(thresh=round(untreated.shape[1]/2))\n",
    "\n",
    "# preserve labels\n",
    "labels = pd.DataFrame(treated.reset_index().iloc[:,:4])\n",
    "columns = list(treated.iloc[:,3:].columns)\n",
    "labels_untreated = pd.DataFrame(untreated.reset_index().iloc[:,:4])\n",
    "columns_untreated = list(untreated.iloc[:,3:].columns)\n",
    "\n",
    "# Make an instance and perform the imputation\n",
    "print('\\nImputing by Case/Control (this make take several minutes)')\n",
    "start_time = time.time()\n",
    "k = round(math.sqrt(treated.iloc[:,3:].shape[1]))\n",
    "k2 = round(math.sqrt(untreated.iloc[:,3:].shape[1]))\n",
    "imputer = KNNImputer(n_neighbors=k)\n",
    "imputer2 = KNNImputer(n_neighbors=k2)\n",
    "a = imputer.fit_transform(treated.iloc[:,3:])\n",
    "a = labels.join(pd.DataFrame(a, columns = columns))\n",
    "b = imputer2.fit_transform(untreated.iloc[:,3:])\n",
    "b = labels_untreated.join(pd.DataFrame(b, columns = columns_untreated))\n",
    "print('Time to impute: %s minutes' % round((time.time() - start_time)/60, 2))\n",
    "\n",
    "# repiece and export\n",
    "imputed = a.merge(b, how='inner').drop(columns=['index'])\n",
    "# Apply log2 to each column\n",
    "log2_imputed = imputed.iloc[:,3:].apply(lambda x: np.log2(x), axis=0)\n",
    "log2_imputed = imputed.iloc[:,:3].join(log2_imputed)\n",
    "log2_imputed = log2_imputed.dropna()\n",
    "DEA_df = imputed.dropna()\n",
    "imputed = imputed.dropna()\n",
    "print(nan_check(imputed))\n",
    "imputed.to_csv(f'{path}/{Experiment}_{Plate}_Imputed_{Date}.csv')\n",
    "\n",
    "### SPLIT! for Single Cell/Bulk ###\n",
    "if WASP_pipeline == '0':\n",
    "    ### Remake Dataframe for Second Imputation\n",
    "    imputed_lba = imputed.iloc[:,:3]\n",
    "\n",
    "    # break df\n",
    "    imputed_treated = imputed.filter(Case.split(','))\n",
    "    imputed_treated = imputed_lba.join(imputed_treated)\n",
    "    imputed_untreated = imputed.filter(Control.split(','))\n",
    "    imputed_untreated = imputed_lba.join(imputed_untreated)\n",
    "    \n",
    "    # Group by File.ID and Master.Protein.Accessions columns and summarize columns 126 to 135N by median\n",
    "    quant_treated = imputed_treated.groupby(['File ID', 'Master Protein Accessions']).agg(Case_Median).reset_index()\n",
    "    quant_untreated = imputed_untreated.groupby(['File ID', 'Master Protein Accessions']).agg(Control_Median).reset_index()\n",
    "    \n",
    "    # Pivot longer to create a 'variable' column with column names\n",
    "    quant_treated = pd.melt(quant_treated, id_vars=['File ID', 'Master Protein Accessions'], var_name='Channel', value_name='Abundance')\n",
    "    quant_untreated = pd.melt(quant_untreated, id_vars=['File ID', 'Master Protein Accessions'], var_name='Channel', value_name='Abundance')\n",
    "\n",
    "    # Create Sample ID\n",
    "    quant_treated['Sample ID'] = quant_treated['Channel'].str.cat(quant_treated['File ID'], sep = '_')\n",
    "    quant_treated = quant_treated.drop(['File ID', 'Channel'], axis=1)\n",
    "    quant_untreated['Sample ID'] = quant_untreated['Channel'].str.cat(quant_untreated['File ID'], sep = '_')\n",
    "    quant_untreated = quant_untreated.drop(['File ID', 'Channel'], axis=1)\n",
    "    \n",
    "    # Pivot wider to create new columns with variable names\n",
    "    quant_treated = quant_treated.pivot(index='Master Protein Accessions', columns=['Sample ID'], values='Abundance')\n",
    "    quant_untreated = quant_untreated.pivot(index='Master Protein Accessions', columns=['Sample ID'], values='Abundance')\n",
    "\n",
    "    # Proteins with > 50% missing values\n",
    "    thresh = round(quant_treated.shape[1]/2)\n",
    "    na_quant_treated = quant_treated.reset_index().reset_index().dropna(axis=0, thresh=thresh)\n",
    "    thresh = round(quant_untreated.shape[1]/2)\n",
    "    na_quant_untreated = quant_untreated.reset_index().reset_index().dropna(axis=0, thresh=thresh)\n",
    "\n",
    "    # preserve labels\n",
    "    labels = pd.DataFrame(na_quant_treated.iloc[:,:2])\n",
    "    columns = list(na_quant_treated.iloc[:,2:].columns)\n",
    "    labels_untreated = pd.DataFrame(na_quant_untreated.iloc[:,:2])\n",
    "    columns_untreated = list(na_quant_untreated.iloc[:,2:].columns)\n",
    "\n",
    "    # Make an instance and perform the imputation\n",
    "    k = round(math.sqrt(quant_treated.shape[1]))\n",
    "    imputer = KNNImputer(n_neighbors=k)\n",
    "    a = pd.DataFrame(imputer.fit_transform(na_quant_treated.iloc[:,2:]), columns = columns)\n",
    "    a['index'] = list(labels['index'])\n",
    "    a['Master Protein Accessions'] = list(labels['Master Protein Accessions'])\n",
    "    cols = a.columns.tolist()\n",
    "    cols = cols[-2:] + cols[:-2]\n",
    "    a = a[cols]\n",
    "    k = round(math.sqrt(quant_untreated.shape[1]))\n",
    "    imputer = KNNImputer(n_neighbors=k)\n",
    "    b = pd.DataFrame(imputer.fit_transform(na_quant_untreated.iloc[:,2:]), columns = columns_untreated)\n",
    "    b['index'] = list(labels_untreated['index'])\n",
    "    b['Master Protein Accessions'] = list(labels_untreated['Master Protein Accessions'])\n",
    "    cols = b.columns.tolist()\n",
    "    cols = cols[-2:] + cols[:-2]\n",
    "    b = b[cols]\n",
    "\n",
    "    # repiece\n",
    "    imputed_2 = a.merge(b, how='inner').set_index('Master Protein Accessions').drop(columns=['index'])\n",
    "\n",
    "    # make dataframe for PCA/UMAP\n",
    "    pcDF = imputed_2.T\n",
    "    mylist = Control.split(',')\n",
    "    pcDF['Sample'] = pcDF.index\n",
    "    pcDF[['Channel', 'File ID']] = pcDF.Sample.str.split(\"_\", expand = True)\n",
    "    pcDF['Treatment'] = np.where(pcDF['Channel'].isin(mylist), 'Control', 'Case')\n",
    "    pcDF['batch'] = pcDF['File ID'].str.replace('F', '')\n",
    "    pgp = pcDF.set_index('Sample')\n",
    "    pgp.pop('Channel')\n",
    "    pgp.pop('File ID')\n",
    "    \n",
    "    # Plot Pre-Combat Noramzalization\n",
    "    plt.figure(figsize=(6,39))\n",
    "    sns.boxenplot(data=pgp.iloc[:,:2].T, orient='h', width_method=\"linear\")\n",
    "    plt.xlabel('Relative Abundance')\n",
    "    plt.ylabel('Channel')\n",
    "    plt.title('Pre-Combat')\n",
    "    plt.savefig(f'{path}/{Experiment}_{Plate}_Pre-Combat_{Date}.pdf', format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "    ### PyCombat Normalization \n",
    "    # make dataframes and labels\n",
    "    print('\\nPerforming PyCombat Batch Normalization for Injection Normalization')\n",
    "    data_t = pgp.iloc[:,:-2].T\n",
    "    data_l = pgp.Treatment\n",
    "    batch = list(pgp.batch)\n",
    "\n",
    "    # combat\n",
    "    data_corrected = pycombat(data_t,batch)\n",
    "    combat = data_corrected.T\n",
    "    combat['Treatment'] = data_l\n",
    "    combat.to_csv(f'{path}/{Experiment}_{Plate}_Combat_{Date}.csv')\n",
    "    print('\\nPost imputation/normalization number of proteins: ' + str(combat.shape[1]))\n",
    "    \n",
    "    # Plot Post-Combat\n",
    "    plt.figure(figsize=(6,39))\n",
    "    sns.boxenplot(data=combat.iloc[:,:2].T, orient='h', width_method=\"linear\")\n",
    "    plt.xlabel('Relative Abundance')\n",
    "    plt.ylabel('Channel')\n",
    "    plt.title('Post-Combat')\n",
    "    plt.savefig(f'{path}/{Experiment}_{Plate}_Post-Combat_{Date}.pdf', format=\"pdf\", bbox_inches=\"tight\")\n",
    "    \n",
    "    # PCA viz\n",
    "    print('\\nPreparing Principal Component Analysis')\n",
    "    df = combat\n",
    "    X = combat.iloc[:,:-1]\n",
    "    X.columns = X.columns.astype(str)\n",
    "    y = combat.Treatment\n",
    "    pca = PCA(n_components=min(X.shape))\n",
    "    components = pca.fit_transform(X)\n",
    "\n",
    "    fig = px.scatter(components, x=0, y=1, color=df['Treatment'], \n",
    "                     labels={\n",
    "                         '0': 'PC 1',\n",
    "                         '1': 'PC 2',\n",
    "                         'color': Plate},\n",
    "                    hover_name = df.index, title='Principal Component Analysis')\n",
    "    fig.show()\n",
    "    fig.write_image(f'{path}/{Experiment}_{Plate}_PCA_{Date}.png')\n",
    "    fig.write_image(f'{path}/{Experiment}_{Plate}_PCA_{Date}.pdf')\n",
    "    \n",
    "    ### PCA nth component allows possibility to perform UMAP on PCs instead of normalized data\n",
    "    # select pcs for 80% variance explained\n",
    "    variance = pca.explained_variance_ratio_\n",
    "    pcs = find80p(variance)\n",
    "    npc = [x+1 for x in range(pcs)]\n",
    "    PC_str = 'PC '\n",
    "\n",
    "    # make PC_df Col labels\n",
    "    PCA_cols = prepend(npc, PC_str)\n",
    "    pca = PCA(n_components=pcs, svd_solver = 'auto')\n",
    "    Principal_components=pca.fit_transform(X)\n",
    "    pca_df = pd.DataFrame(data = Principal_components, columns = PCA_cols)\n",
    "    pca_df['Treatment'] = list(y)\n",
    "\n",
    "    # UMAP on principle components\n",
    "    print('\\nGenerating UMAP')\n",
    "    features = X\n",
    "\n",
    "    umap_2d = UMAP(n_components=2, n_neighbors=15, min_dist=0.75, n_epochs=5000, \n",
    "                   random_state=42)\n",
    "    umap_3d = UMAP(n_components=3, n_neighbors=15, min_dist=0.75, n_epochs=5000, \n",
    "                   random_state=42)\n",
    "\n",
    "    proj_2d = umap_2d.fit_transform(features)\n",
    "    proj_3d = umap_3d.fit_transform(features)\n",
    "\n",
    "    fig_2d = px.scatter(\n",
    "        proj_2d, x=0, y=1,\n",
    "        color=df.Treatment,\n",
    "        labels={\n",
    "            0: '',\n",
    "            1: '',\n",
    "            'color': Plate},\n",
    "        hover_name=combat.index,\n",
    "        title='Uniform Manifold Approximation & Projection'\n",
    "    )\n",
    "    fig_2d.update_traces(marker_size=10)\n",
    "\n",
    "    fig_3d = px.scatter_3d(\n",
    "        proj_3d, x=0, y=1, z=2,\n",
    "        color=df.Treatment,\n",
    "        labels={\n",
    "            0: '',\n",
    "            1: '',\n",
    "            2: '',\n",
    "            'color': Plate},\n",
    "        hover_name=combat.index,\n",
    "        title='Uniform Manifold Approximation & Projection'\n",
    "    )\n",
    "    fig_3d.update_traces(marker_size=5)\n",
    "\n",
    "    fig_2d.show()\n",
    "    fig_3d.show()\n",
    "\n",
    "    fig_2d.write_image(f'{path}/{Experiment}_{Plate}_UMAP_2D_{Date}.png')\n",
    "    fig_3d.write_image(f'{path}/{Experiment}_{Plate}_UMAP_3D_{Date}.png')\n",
    "    fig_2d.write_image(f'{path}/{Experiment}_{Plate}_UMAP_2D_{Date}.pdf')\n",
    "    fig_3d.write_image(f'{path}/{Experiment}_{Plate}_UMAP_3D_{Date}.pdf')\n",
    "\n",
    "    ### Heatmap and Top 100 eigenvectors\n",
    "    # get top 100 eigenvectors from PC1\n",
    "    print('\\nGetting Top 100 Eigenvectors')\n",
    "    p = pd.DataFrame(abs( pca.components_ ))\n",
    "    p.columns = combat.columns[0:-1]\n",
    "    hm = p.T.sort_values(by=0, ascending=False).head(101)\n",
    "\n",
    "    # Group by File.ID and Master.Protein.Accessions columns and summarize columns 126 to 135N by sum\n",
    "    agg = DEA_df.groupby(['Master Protein Accessions']).agg(Heatmap_agg).reset_index()\n",
    "    heatmap = agg.loc[agg['Master Protein Accessions'].isin(hm.index)].set_index('Master Protein Accessions')\n",
    "    heatmap_csv = round(heatmap, 2)\n",
    "    round(heatmap_csv, 1).to_excel(f'{path}/{Experiment}_{Plate}_Heatmap_Matrix_{Date}.xlsx')\n",
    "\n",
    "    # Visualize Heatmap\n",
    "    print('\\nTop 40 Eigenvectors Heatmap')\n",
    "    fig, ax = plt.subplots(figsize=(9, 9))\n",
    "    sns.set(font_scale=0.9)\n",
    "    heatmap_data = heatmap.head(40).apply(lambda x: np.log2(x), axis=0)\n",
    "    hmll = np.where(heatmap.columns.isin(mylist), 'Control', 'Case')\n",
    "    HMViz = sns.heatmap(heatmap_data, xticklabels=hmll, yticklabels=True, linewidth=.5)\n",
    "    HMViz.set_xticklabels(HMViz.get_xticklabels(), rotation=360, ha='center', size='x-small')\n",
    "    \n",
    "    HMfig = HMViz.get_figure()\n",
    "    HMfig.savefig(f'{path}/{Experiment}_{Plate}_Heatmap_{Date}.png')\n",
    "    HMfig.savefig(f'{path}/{Experiment}_{Plate}_Heatmap_{Date}.pdf')\n",
    "\n",
    "    ### Map Gene Symbol to Protein Accession\n",
    "    # read file\n",
    "    print('\\nMapping Gene Symbol to Protein Accessions')\n",
    "    ev = hm\n",
    "\n",
    "    # rename Gene column and remove white space\n",
    "    UniProt.rename(columns={'Gene Names': 'Gene Symbol', 'Entry': 'Master Protein Accessions', 'Protein names': 'Protein.Names'},\n",
    "                   inplace=True)\n",
    "    UniProt.drop(['Protein.Names'], axis = 1, inplace=True)\n",
    "    UniProt['Gene Symbol'] = UniProt['Gene Symbol'].str.split(' ').str[0]\n",
    "\n",
    "    # make dataframe\n",
    "    ev = ev.reset_index()\n",
    "    ev['Gene Symbol'] = ''\n",
    "    cllist = [x for x in range(len(ev.columns)-2)]\n",
    "    output = []\n",
    "    nested_cols = ['Master Protein Accessions', 'Gene Symbol', cllist]\n",
    "    reemovNestings(nested_cols)\n",
    "    cols = output\n",
    "    ev = ev[output]\n",
    "    ev['Master Protein Accessions'] = ev['Master Protein Accessions'].str.split('; ').str[0]\n",
    "\n",
    "    # merge\n",
    "    mapped = pd.merge(UniProt, ev, on = 'Master Protein Accessions', how = 'right')\n",
    "\n",
    "    # clean\n",
    "    mapped.drop(['Gene Symbol_y'], axis=1, inplace=True)\n",
    "    mapped.rename(columns={'Gene Symbol_x': 'Gene Symbol'},inplace=True)\n",
    "    mapped.rename(columns=dict(zip(cllist, PCA_cols)), inplace=True)\n",
    "\n",
    "    # find unmapped Genes\n",
    "    print('\\n' + str(mapped['Gene Symbol'].isna().sum()) + ' IDs were not mapped')\n",
    "    mapped.replace(np.NaN, 'NaN', inplace=True)\n",
    "    for i in range(mapped.shape[0]):\n",
    "        if mapped['Gene Symbol'].iloc[i] == 'NaN':\n",
    "            print(mapped['Master Protein Accessions'].iloc[i])\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    # export\n",
    "    round(mapped, 3).to_excel(f'{path}/{Experiment}_{Plate}_100Eigenvectors_{Date}.xlsx')\n",
    "\n",
    "    ### Differential Expression Analysis\n",
    "    # Prepare DF\n",
    "    #DEA_df = DEA_imputed\n",
    "    DEA_df = DEA_df.groupby(['Master Protein Accessions']).agg(DEA_agg).reset_index()\n",
    "    counts = DEA_df.set_index('Master Protein Accessions').T.astype('int')\n",
    "    clinical = DEA_df.set_index('Master Protein Accessions').T\n",
    "    clinical = pd.DataFrame(clinical.index)\n",
    "    clinical['Treatment'] = np.where(clinical[0].isin(mylist), 'Control', 'Treatment')\n",
    "    clinical = clinical.set_index(0)\n",
    "\n",
    "    # Build Model\n",
    "    dds = DeseqDataSet(\n",
    "        counts=counts,\n",
    "        clinical=clinical,\n",
    "        design_factors='Treatment',\n",
    "        refit_cooks=True,\n",
    "        n_cpus=8)\n",
    "\n",
    "    # Run DESeq2\n",
    "    print('\\nRunning DESeq2')\n",
    "    dds.deseq2()\n",
    "\n",
    "    stat_res = DeseqStats(dds, n_cpus=8)\n",
    "    stats = round(pd.DataFrame(stat_res.summary()), 2)\n",
    "\n",
    "    round(stat_res.results_df, 3).to_excel(f'{path}/{Experiment}_{Plate}_Log2FC_WaldP-value_Proteins_{Date}.xlsx')\n",
    "\n",
    "    ### Map Gene Symbol to Protein Accession\n",
    "    # read file\n",
    "    print('\\nMapping Gene Symbol to Protein Accessions')\n",
    "    RegulatedProteins = stat_res.results_df\n",
    "    RegulatedProteins.rename(columns={'baseMean': 'Base Mean', 'log2FoldChange': 'log2 Fold Change', 'pvalue': 'P-value'},\n",
    "                            inplace=True)\n",
    "    RegulatedProteins.drop(['lfcSE', 'stat', 'padj'], axis=1, inplace=True)\n",
    "    RegulatedProteins['Gene Symbol'] = ''\n",
    "    RegulatedProteins['Fold Change'] = 2**RegulatedProteins['log2 Fold Change']\n",
    "    RP = ['Gene Symbol', 'Base Mean', 'log2 Fold Change', 'Fold Change', 'P-value']\n",
    "    RegulatedProteins = RegulatedProteins[RP]\n",
    "    RegulatedProteins.reset_index(inplace=True)\n",
    "    RegulatedProteins['Master Protein Accessions'] = RegulatedProteins['Master Protein Accessions'].str.split('; ').str[0]\n",
    "\n",
    "    # merge\n",
    "    mapped = pd.merge(UniProt, RegulatedProteins, on = 'Master Protein Accessions', how = 'right')\n",
    "\n",
    "    # clean\n",
    "    mapped.drop(['Gene Symbol_y'], axis=1, inplace=True)\n",
    "    mapped.rename(columns={'Gene Symbol_x': 'Gene Symbol'},inplace=True)\n",
    "    mapped.rename(columns=dict(zip(cllist, PCA_cols)), inplace=True)\n",
    "    \n",
    "    # Volcano Plot with Protein Names\n",
    "    try:\n",
    "        visuz.GeneExpression.volcano(df=mapped.dropna(), lfc='log2 Fold Change', pv='P-value',\n",
    "                                     lfc_thr=(0.58, 0.58), geneid='Master Protein Accessions',\n",
    "                                     genenames='deg', gfont=4, color= ('red', 'grey', 'blue'), sign_line=True)\n",
    "    except AssertionError:\n",
    "        print('\\nNo Significantly, Differentially Abundant Proteins')\n",
    "        pass\n",
    "\n",
    "    # find unmapped Genes\n",
    "    print('\\n' + str(mapped['Gene Symbol'].isna().sum()) + ' IDs were not mapped')\n",
    "    mapped.replace(np.NaN, 'NaN', inplace=True)\n",
    "    for i in range(mapped.shape[0]):\n",
    "        if mapped['Gene Symbol'].iloc[i] == 'NaN':\n",
    "            print(mapped['Master Protein Accessions'].iloc[i])\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    # export\n",
    "    round(mapped, 3).to_excel(f'{path}/{Experiment}_{Plate}_log2FC_WaldP-value_Genes_{Date}.xlsx')\n",
    "\n",
    "    print('\\n\\nProgram Complete')\n",
    "\n",
    "else:\n",
    "    ### BULK\n",
    "    # make dataframe for PCA/UMAP\n",
    "    pcDF = DEA_df.iloc[:,3:].T\n",
    "    mylist = Control.split(',')\n",
    "    pcDF['Sample'] = pcDF.index\n",
    "    pcDF['Treatment'] = np.where(pcDF['Sample'].isin(mylist), 'Control', 'Case')\n",
    "    pgp = pcDF.set_index('Sample')\n",
    "\n",
    "    # PCA\n",
    "    print('\\nPreparing Principal Component Analysis')\n",
    "    df = pgp\n",
    "    X = pgp.iloc[:,:-3]\n",
    "    X.columns = X.columns.astype(str)\n",
    "    y = pgp.Treatment\n",
    "    pca = PCA(n_components=min(X.shape))\n",
    "    components = pca.fit_transform(X)\n",
    "\n",
    "    fig = px.scatter(components, x=0, y=1, color=df['Treatment'],\n",
    "                     labels={\n",
    "                         0: 'PC 1',\n",
    "                         1: 'PC 2',\n",
    "                         'color': Plate},\n",
    "                     text=pgp.index, title='Principal Component Analysis')\n",
    "    fig.update_traces(textposition='top center')\n",
    "    fig.update_traces(marker_size=10)\n",
    "    fig.show()\n",
    "    fig.write_image(f'{path}/{Experiment}_{Plate}_Bulk_PCA_{Date}.png')\n",
    "    fig.write_image(f'{path}/{Experiment}_{Plate}_Bulk_PCA_{Date}.pdf')\n",
    "\n",
    "    ### PCA nth component allows possibility to perform UMAP on PCs instead of normalized data \n",
    "    # select pcs for 80% variance explained\n",
    "    variance = pca.explained_variance_ratio_\n",
    "    pcs = find80p(variance)\n",
    "    npc = [x+1 for x in range(pcs)]\n",
    "    PC_str = 'PC '\n",
    "\n",
    "    # make PC_df Col labels\n",
    "    PCA_cols = prepend(npc, PC_str)\n",
    "    pca = PCA(n_components=pcs, svd_solver = 'auto')\n",
    "    Principal_components=pca.fit_transform(X)\n",
    "    pca_df = pd.DataFrame(data = Principal_components, columns = PCA_cols)\n",
    "    pca_df['Treatment'] = list(y)\n",
    "\n",
    "    # UMAP on principle components\n",
    "    print('\\nGenerating UMAP')\n",
    "    features = X\n",
    "\n",
    "    umap_2d = UMAP(n_components=2, n_neighbors=len(Case.split(',')), n_epochs=5000, \n",
    "                   random_state=42)\n",
    "    umap_3d = UMAP(n_components=3, n_neighbors=len(Case.split(',')), n_epochs=5000, \n",
    "                   random_state=42)\n",
    "\n",
    "    proj_2d = umap_2d.fit_transform(features)\n",
    "    proj_3d = umap_3d.fit_transform(features)\n",
    "\n",
    "    fig_2d = px.scatter(\n",
    "        proj_2d, x=0, y=1,\n",
    "        color=df.Treatment,\n",
    "        labels={\n",
    "            0: '',\n",
    "            1: '',\n",
    "            'color': Plate},\n",
    "        hover_name=df.index,\n",
    "        text=pgp.index,\n",
    "        title='Uniform Manifold Approximation & Projection'\n",
    "    )\n",
    "    fig_2d.update_traces(textposition='top center')\n",
    "    fig_2d.update_traces(marker_size=10)\n",
    "\n",
    "    fig_3d = px.scatter_3d(\n",
    "        proj_3d, x=0, y=1, z=2,\n",
    "        color=df.Treatment,\n",
    "        labels={\n",
    "            0: '',\n",
    "            1: '',\n",
    "            2: '',\n",
    "            'color': Plate},\n",
    "        text=df.index,\n",
    "        title='Uniform Manifold Approximation & Projection'\n",
    "    )\n",
    "    fig_3d.update_traces(textposition='top center')\n",
    "    fig_3d.update_traces(marker_size=5)\n",
    "\n",
    "    fig_2d.show()\n",
    "    fig_3d.show()\n",
    "\n",
    "    fig_2d.write_image(f'{path}/{Experiment}_{Plate}_Bulk_UMAP_2D_{Date}.png')\n",
    "    fig_3d.write_image(f'{path}/{Experiment}_{Plate}_Bulk_UMAP_3D_{Date}.png')\n",
    "    fig_2d.write_image(f'{path}/{Experiment}_{Plate}_Bulk_UMAP_2D_{Date}.pdf')\n",
    "    fig_3d.write_image(f'{path}/{Experiment}_{Plate}_Bulk_UMAP_3D_{Date}.pdf')\n",
    "    \n",
    "    ### Differential Expression Analysis\n",
    "    # Prepare DF\n",
    "    #DEA_df = DEA_imputed\n",
    "    DEA_df = DEA_df.groupby(['Master Protein Accessions']).agg(DEA_agg).reset_index()\n",
    "    counts = DEA_df.set_index('Master Protein Accessions').T.astype('int')\n",
    "    clinical = DEA_df.set_index('Master Protein Accessions').T\n",
    "    clinical = pd.DataFrame(clinical.index)\n",
    "    clinical['Treatment'] = np.where(clinical[0].isin(mylist), 'Control', 'Treatment')\n",
    "    clinical = clinical.set_index(0)\n",
    "\n",
    "    # Build Model\n",
    "    dds = DeseqDataSet(\n",
    "        counts=counts,\n",
    "        clinical=clinical,\n",
    "        design_factors='Treatment',\n",
    "        refit_cooks=True,\n",
    "        n_cpus=8)\n",
    "\n",
    "    # Run DESeq2\n",
    "    print('\\nRunning DESeq2')\n",
    "    dds.deseq2()\n",
    "\n",
    "    stat_res = DeseqStats(dds, n_cpus=8)\n",
    "    stats = round(pd.DataFrame(stat_res.summary()), 2)\n",
    "\n",
    "    round(stat_res.results_df, 3).to_excel(f'{path}/{Experiment}_{Plate}_Bulk_Log2FC_WaldP-value_Proteins_{Date}.xlsx')\n",
    "\n",
    "    ### Map Gene Symbol to Protein Accession\n",
    "    # read file\n",
    "    print('\\nMapping Gene Symbol to Protein Accessions')\n",
    "    RegulatedProteins = stat_res.results_df\n",
    "    RegulatedProteins.rename(columns={'baseMean': 'Base Mean', 'log2FoldChange': 'log2 Fold Change', 'pvalue': 'P-value'},\n",
    "                            inplace=True)\n",
    "    RegulatedProteins.drop(['lfcSE', 'stat', 'padj'], axis=1, inplace=True)\n",
    "    RegulatedProteins['Gene Symbol'] = ''\n",
    "    RegulatedProteins['Fold Change'] = 2**RegulatedProteins['log2 Fold Change']\n",
    "    RP = ['Gene Symbol', 'Base Mean', 'log2 Fold Change', 'Fold Change', 'P-value']\n",
    "    RegulatedProteins = RegulatedProteins[RP]\n",
    "    RegulatedProteins.reset_index(inplace=True)\n",
    "    RegulatedProteins['Master Protein Accessions'] = RegulatedProteins['Master Protein Accessions'].str.split('; ').str[0]\n",
    "\n",
    "    # rename Gene column and remove white space\n",
    "    UniProt.rename(columns={'Gene Names': 'Gene Symbol', 'Entry': 'Master Protein Accessions', 'Protein names': 'Protein.Names'},\n",
    "                   inplace=True)\n",
    "    UniProt.drop(['Protein.Names'], axis = 1, inplace=True)\n",
    "    UniProt['Gene Symbol'] = UniProt['Gene Symbol'].str.split(' ').str[0]\n",
    "\n",
    "    # merge\n",
    "    mapped = pd.merge(UniProt, RegulatedProteins, on = 'Master Protein Accessions', how = 'right')\n",
    "\n",
    "    # clean\n",
    "    mapped.drop(['Gene Symbol_y'], axis=1, inplace=True)\n",
    "    mapped.rename(columns={'Gene Symbol_x': 'Gene Symbol'},inplace=True)\n",
    "\n",
    "    # Volcano Plot with Protein Names\n",
    "    try:\n",
    "        visuz.GeneExpression.volcano(df=mapped.dropna(), lfc='log2 Fold Change', pv='P-value',\n",
    "                                     lfc_thr=(0.58, 0.58), geneid='Master Protein Accessions',\n",
    "                                     genenames='deg', gfont=4, color= ('red', 'grey', 'blue'), sign_line=True)\n",
    "    except AssertionError:\n",
    "        print('\\nNo Significantly, Differentially Abundant Proteins')\n",
    "        pass\n",
    "                         \n",
    "    # find unmapped Genes\n",
    "    print('\\n' + str(mapped['Gene Symbol'].isna().sum()) + ' IDs were not mapped')\n",
    "    mapped.replace(np.NaN, 'NaN', inplace=True)\n",
    "    for i in range(mapped.shape[0]):\n",
    "        if mapped['Gene Symbol'].iloc[i] == 'NaN':\n",
    "            print(mapped['Master Protein Accessions'].iloc[i])\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    # export\n",
    "    round(mapped, 3).to_excel(f'{path}/{Experiment}_{Plate}_Bulk_log2FC_WaldP-value_Genes_{Date}.xlsx')\n",
    "\n",
    "    print('\\n\\nProgram Complete')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861d8680",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
